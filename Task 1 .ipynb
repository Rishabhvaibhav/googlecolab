{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www.apache.org/dyn/closer.lua/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "3MeDZ07c5lfl",
        "outputId": "79972905-41d9-41a2-d55d-a912e22c58bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from pyspark) (0.10.9.5)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.8/dist-packages (0.10.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"Colab\").config('spark.ui.port','4050').getOrCreate()"
      ],
      "metadata": {
        "id": "nxo5ZaTS5pHa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the greatest function**"
      ],
      "metadata": {
        "id": "3tA7_TphCS_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import greatest\n",
        "\n",
        "# first i create a Create a DataFrame\n",
        "df = spark.createDataFrame([(1, 2, 3), (4, 5, 6), (7, 8, 9)], [\"col1\", \"col2\", \"col3\"])\n",
        "\n",
        "df.select(greatest(\"col1\", \"col2\", \"col3\").alias(\"greatest\")).show()"
      ],
      "metadata": {
        "id": "3ZpOBCTSCNgW",
        "outputId": "3f1b4535-f24d-4169-d62a-f7263587e660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|greatest|\n",
            "+--------+\n",
            "|       3|\n",
            "|       6|\n",
            "|       9|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the split function**"
      ],
      "metadata": {
        "id": "1_6vTNzCCc8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import split\n",
        "\n",
        "# Create a DataFrame\n",
        "df2 = spark.createDataFrame([(\"a,b,c\",)], [\"text\"])\n",
        "\n",
        "df2.select(split(\"text\", \",\").alias(\"text\")).show(truncate=False)\n"
      ],
      "metadata": {
        "id": "_oMiEYvpATrw",
        "outputId": "fe562e18-d1f9-4f43-f154-f5eb286bfa93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|text     |\n",
            "+---------+\n",
            "|[a, b, c]|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the least function**"
      ],
      "metadata": {
        "id": "ZVjpeM4zC2bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import least\n",
        "\n",
        "df.select(least(\"col1\", \"col2\", \"col3\").alias(\"least\")).show()\n"
      ],
      "metadata": {
        "id": "d20alzy3ATpN",
        "outputId": "31e77dd1-33b7-4789-9929-b235c2bef4d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|least|\n",
            "+-----+\n",
            "|    1|\n",
            "|    4|\n",
            "|    7|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the len function**"
      ],
      "metadata": {
        "id": "t8AXuG9gDYYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "# Create a DataFrame\n",
        "df3 = spark.createDataFrame([[\"Pritam\", 30], [\"Rishabh\", 25], [\"Shubham\", 40]], [\"name\", \"age\"])\n",
        "\n",
        "df3.select(F.length(\"name\").alias(\"length\")).show()\n"
      ],
      "metadata": {
        "id": "s6iW6dz3ATml",
        "outputId": "7e2cf1ef-4588-4fd1-f9a2-d691ed0eafac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|length|\n",
            "+------+\n",
            "|     6|\n",
            "|     7|\n",
            "|     7|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the lower function**"
      ],
      "metadata": {
        "id": "adW5dbqPFsPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lower\n",
        "\n",
        "# Create a DataFrame\n",
        "df = spark.createDataFrame([(\"ABC\",), (\"DEF\",)], [\"text\"])\n",
        "\n",
        "df.select(lower(\"text\").alias(\"lower_case\")).show()\n"
      ],
      "metadata": {
        "id": "oKVOmVQEATj3",
        "outputId": "906594d0-76f2-4a21-bbf4-c89507ab3b75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|lower_case|\n",
            "+----------+\n",
            "|       abc|\n",
            "|       def|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the max function**"
      ],
      "metadata": {
        "id": "RZtOkT8AF2JN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import max\n",
        "\n",
        "df = spark.createDataFrame([(1, 2, 3), (4, 5, 6), (7, 8, 9)], [\"col1\", \"col2\", \"col3\"])\n",
        "\n",
        "df.agg({'col1': 'max','col2': 'max','col3': 'max'}).show()\n"
      ],
      "metadata": {
        "id": "toU0uwiXATg8",
        "outputId": "29c992c1-d2a1-4e77-9b8c-e23373f34c87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---------+\n",
            "|max(col2)|max(col3)|max(col1)|\n",
            "+---------+---------+---------+\n",
            "|        8|        9|        7|\n",
            "+---------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the higher function**"
      ],
      "metadata": {
        "id": "0uP30basIkqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark.sql.functions import higher\n",
        "\n",
        "# this Question is Wrong becz there have no any function od higher in pyspark MAximum\\]\n",
        "\n"
      ],
      "metadata": {
        "id": "b8NGZ0aiATeD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the `mean` function to calculate the mean value**"
      ],
      "metadata": {
        "id": "tgLnjvGtOoRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean\n",
        "\n",
        "df = spark.createDataFrame([(1, 2, 3), (4, 5, 6), (7, 8, 9)], [\"col1\", \"col2\", \"col3\"])\n",
        "df.select(mean(\"col1\")).show()\n"
      ],
      "metadata": {
        "id": "GfWHyNUkATbX",
        "outputId": "dc253f34-699e-43d0-da34-6eec9feccebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|avg(col1)|\n",
            "+---------+\n",
            "|      4.0|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the `round` function to round the values in a column**"
      ],
      "metadata": {
        "id": "pj2o5qkUOsFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import round\n",
        "\n",
        "df.select(round(\"col1\", 2)).show()\n"
      ],
      "metadata": {
        "id": "nIt8nNo1ATIG",
        "outputId": "a23995ee-01f8-4ea4-9900-02c14e1642b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|round(col1, 2)|\n",
            "+--------------+\n",
            "|             1|\n",
            "|             4|\n",
            "|             7|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the `collect_set` function to create a set of the values in a column**"
      ],
      "metadata": {
        "id": "tDkIfAqBO0Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import collect_set\n",
        "\n",
        "df.select(collect_set(\"col1\")).show()\n"
      ],
      "metadata": {
        "id": "kI7-HN5iOMFS",
        "outputId": "a22552d9-5408-4728-c500-ca22c848d359",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|collect_set(col1)|\n",
            "+-----------------+\n",
            "|        [1, 7, 4]|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the `collect_list` function to create a list of the values in a column**"
      ],
      "metadata": {
        "id": "IlFdYK_tO4Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import collect_list\n",
        "\n",
        "df.select(collect_list(\"col1\")).show()\n"
      ],
      "metadata": {
        "id": "9g9iouPEOL8S",
        "outputId": "8917d224-1637-4f8e-a024-231b6fb43752",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|collect_list(col1)|\n",
            "+------------------+\n",
            "|         [1, 4, 7]|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vn675P7TO5yu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}